---
layout: index
title: Zhengjiang Lin
---
{% include JB/setup %}

<div>
<div style="float:left;padding:13px">
  <img src="{{ BASE_PATH }}/data/img/tqchen-head.jpg" height="230px">
</div>
<div style="padding:15px;padding-left:20px">
<h1> Tianqi Chen </h1>
<ul style="list-style-type:none">
  <li>
    <b>Ph.D. student</b>
  <li>
    <a href="http://www.cs.washington.edu">Paul G. Allen School of Computer Science and Engineering</a>
  <li>
    <a href="http://www.washington.edu">University of Washington</a>
<li>
<li>
  <b>Email</b>: <a>tqchen@cs.washington.edu</a> </li>
<li>
  <b>Google Scholar: </b><a href="https://scholar.google.com/citations?user=pdf2nkgAAAAJ">Tianqi Chen</a>
<li>
  <b>Github</b>: <a href="https://github.com/tqchen">@tqchen</a>
<li>
  <b>Twitter</b>: <a href="https://twitter.com/tqchenml">@tqchenml</a>
<li>
</div>

<p>
  I am a doubi.
</p>

<h2>Research</h2>
<p>
I am interested in the intersection of machine learning and systems.
The real excitement of this area comes from what can enable
when we bring advanced learning techniques and system together.
On that end, I am also pushing the direction on deep learning,
knowledge transfer and lifelong learning.</br></p>

<p>
Recently, I am working on <a href="https://tvm.ai">TVM stack</a>.
Together with collaborators from <a href="https://sampl.cs.washington.edu">SAMPL Lab</a>,
we co-design systems, machine learning algorithms, architecture,
and programming language to enable future intelligent systems.
</p>

<p>
I build machine learning systems that are widely adopted.
Besides TVM, the two other noticable ones are:
</p>

<ul>
  <li> <a href="https://xgboost.ai"> XGBoost</a>, a scalable tree boosting system. </br>
    It is one of the de-facto tools used by data scientists daily.
    You can find it in the production pipelines of the many major companies such as
    Uber, Airbnb, Amazon and Google Cloud.
    It has also been used to predict interesting physics events in LHC.
  <li> <a href="https://mxnet.incubator.apache.org/">Apache MXNet</a>(co-creator) </br>
    One of the major deep learning frameworks, it is currently adopted by AWS.
</ul>

<p>
I am graduating in 2019, and am on the job market this year.
</p>

<h2>Experience</h2>
<ul>
  <li>
    <p>
      University of Washington, 2013 - present <br>
      Ph.D. student with <a href="http://homes.cs.washington.edu/~guestrin/">Carlos Guestrin</a>.
    </p>
  <li>
    <p>
      Google Brain. Summer 2015</br>
      Research Intern with <a href="https://www.iangoodfellow.com/">Ian Goodfellow</a>.
    </p>
  <li>
    <p>
      Graphlab Inc. Summer 2014</br>
      Intern,  main author of boosted tree and neural net toolkit in Graphlab Create.
    </p>
  <li>
    <p>
      Apex Data and Knowledge Management Lab, Shanghai Jiao Tong University, China. 2010-2013</br>
      Master Student with <a href="http://apex.sjtu.edu.cn/members/yyu">Yong Yu</a>
    </p>
  <li>
    <p>
      System Biology Lab, Shanghai Jiao Tong University. 2010 - 2013</br>
      Visiting Student, with <a href="http://systemsbiology.sjtu.edu.cn/members/Ping_Ao.html">Ping Ao</a>
    </p>
  <li>
    <p>
      Huawei Noah's Ark Lab, Hong Kong. Summer 2012</br>
      Research Intern,  with <a href="http://www.hangli-hl.com/">Hang Li</a> and <a href="http://www.cs.ust.hk/~qyang/">Qiang Yang</a>
    </p>
  <li>
    <p>
      Digital Enterprise Research Institute, Galway, Ireland. Winter 2011</br>
      Visiting Scholar.
    </p>
  <li>
    <p>
      Microsoft Research Asia, Beijing, China. Summer 2009. </br>
      Research Intern, with Jun Yan.
    </p>
</ul>


<h2>Awards</h2>
<ul>
  <li> Google Ph.D. Fellowship
  <li> Champion in of KDD Cup 2012, track1, team leader.
  <li> 3rd place in KDDCup 2011, joint team leader.
</ul>


<h2>Activity and Services</h2>
<ul>
  <li> Organizer of the LearningSys workshop, NIPS 2015.
  <li> Reviewer of ICML, IJCAI, NIPS, ICLR, JMLR, TIST
</ul>
</div>
